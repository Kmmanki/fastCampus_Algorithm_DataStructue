# TIL 2022-05-09 KAFKA

## 1. KAFKA란
메세지 큐 서비스 
producer가 메세지를 제공 -> KAFKA에 저장 -> consumer가 메세지 소비
API 중계기같은 느낌 만약 API 요청이 감당 안될 정도로 들어오게 되면 서버가 뻗어버리지만
KAFKA가 중간에 있다면 서버는 자기가 감당 가능한 만큼만 **소비** 하게됨

## 2. 카프카 구조
카프카는 반드시 zookeeper와 함께 구동이 되어야하며 zoopeeper는 카프카클러스터를 관리하는 역할
아래 이미지의 broker는 하나의 카프카 컨테이너를 의미

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile26.uf.tistory.com%2Fimage%2F99745A4B5E633AF32148ED">



-------------------------

브로커(카프카)는 다수의 토픽(DB의 테이블과 유사)을 가지며 토픽 내부에는 파티션 단위로 데이터가 분산저장되어 있다.
각각의 파티션은 offset을 가지고 있으며 소비가 되면 **offset**이 증가되어 다음 메세지를 소비 할 수 있게 한다.

1개의 토픽은 1개의 ConsumerGroup 소비할 수 있으며 ConsumerGroup은 다수의 Consumer로 구성된다.
- Topic : ConsumerGroup = 1:1

파티션은 한번에 1개의 컨수머만이 접근 할 수 있다. (Lock)
그렇기 때문에 컨수머의 수 보다 파티션이 적을 경우 메시지를 받지 못하는 컨수머가 존자 핼 수 있으므로 컨수머의 수 보다 파티션의 수가 더 크게 한다.
- Partition : Comsumer = 1:1 (접근 시)
- Partition의 수 >= Consumer의 수

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile9.uf.tistory.com%2Fimage%2F998728405E6370AA1FC4A9">

## 2-2 Replication
토픽을 생성 할 시 --replication-factor 옵션을 사용하여 파티션의 복제봊을 생성 할 수 있다.
다수의 브로커(카프카)에 파티션을 복제함으로써 고가용성을 보장한다(하나의 파티션이 동작 할 수 없을 때 복재본의 파티션을 사용)

- leader 파티션이 사용이 불가하게 되면 follower가 leader 파티션이 된다.

아래 그림은 3개의 브로커서버(카프카), 1개의 토픽, 4개의 파티션, 2개의 레프리케이션 펙터 설정 이미지

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile29.uf.tistory.com%2Fimage%2F99BB734B5E63C87925F7EF">

## 3 카프카 설치

docker-compose.yml
```

version: '2'
services:
 zookeeper:
  container_name: local_zookeeper
  image: wurstmeister/zookeeper
  ports:
   - "2181:2181"
  networks:
   - default
 kafka:
  container_name: local_kafka
  image: wurstmeister/kafka
  #zookeeper가 먼저 실행되어야 하기 때문에 depends_on 옵션을 사용하여 후순위 기동
  depends_on:
   - zookeeper
  ports:
   #kafka 기본 포트
   - "9092:9092"
   #추후 prometheus와 연동하게 될 node_exporter 포트
   - "1234:1234"
  environment:
   KAFKA_ADVERTISED_HOST_NAME: 127.0.0.1
   KAFKA_ADVERTISED_PORT: 9092
   #test_topic이라는 이름의 토픽 생성, 파티션은 1개, 레플리케이션은 없음
   KAFKA_CREATE_TOPICS: "test_topic:1:1"
   #주키퍼 관련 환경변수
   KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
   
   #추후 prometheus와 연동할 node_exporter 관련 설정
#   KAFKA_OPTS: -javaagent:/etc/node_exporter/jmx_prometheus_javaagent-0.12.0.jar=1234:/etc/node_exporter/exporter_config.yml
   EXTRA_ARGS: "-javaagent:/etc/node_exporter/jmx_prometheus_javaagent-0.12.0.jar=1234:/etc/node_exporter/exporter_config.yml"
#   TZ: Asia/Seoul
  volumes:
   # kafka 테스트 해보기용 파일 https://www.apache.org/dyn/closer.cgi?path=/kafka/0.10.2.0/kafka_2.12-0.10.2.0.tgz
   - "C:/Users/R14280/Desktop/test/kafkaTest/kafka_2.13-3.1.0:/root"
   #컨테이너를 삭제해도 유지 되도록 볼륨설정
   - "C:/Users/R14280/Desktop/test/kafkaTest/data:/var/lib/kafka/data"
   - /var/run/docker.sock:/var/run/docker.sock
   #node_exporter jar및 config 파일
   - "C:/Users/R14280/Desktop/test/kafkaTest/node_exporter:/etc/node_exporter"
  networks:
   - default
   - prometheus_bridge
#prometheus와 연동시키기 위한 birdge(별도의 compose 파일이기 때문에 네트워크를 생성 후 사용)
networks:
 prometheus_bridge:
  external:
   name: prometheus_bridge
# docker network create prometheus_bridge 생성 후 사용

```
 ### 테스트 방법
 1.$docker exec -it kafka컨테이너 아이디 /bin/bash
 2.$cd /root/bin
 3. kafka-console-producer.sh --broker-list localhost:9092 --topic test_topic
 3-1 3번은 프로듀서를 실행 
 4. 새로운 콘솔로 kafka 컨테이너 접속 및 /root/bin 으로 이동
 5.
 

## 4. 스프링 연동

### 연동 flow
RestAPI로 데이터 전달 -> spring boot에서 Producer 호출하여 데이터를 메시지로 kafka 전달 -> sping boot의 Consumer에서 메세지를 받아 print

----

### build.gradle의 dependencies
- web과 kafka 추가
```

dependencies {
	implementation 'org.springframework.boot:spring-boot-starter-web'
	implementation 'org.springframework.kafka:spring-kafka'
```
-----
### application.yml을 통한 kafka 설정

```
spring:
    kafka:
        consumer:
            bootstrap-servers: localhost:9092
			#컨수머 그룹
            group_id: consumer1
			#카르카로 받아오기 때문에 Deserializer(역직렬화)
            key-desirializer: org.apache.kafka.common.serialization.StringDeserializer
            value-desirializer: org.apache.kafka.common.serialization.StringDeserializer
        producer:
            bootstrap-servers: localhost:9092
			#카프카로 메시지를 전달하기 때문에 Serializer(직렬화)
            key-desirializer: org.apache.kafka.common.serialization.StringSerializer
            value-desirializer: org.apache.kafka.common.serialization.StringSerializer

```
-------

### RestController

```java
@RestController
public class KafkaController {
    
    @Autowired
    private Producer producer;

    @PostMapping("/sendMessage")
    public void sendMessage(String message){
        System.out.println("controller"+ message);
        producer.sendMessage(message);
    }
}
```

### producer
```java
@Service
public class Producer {
    
    @Autowire
    private KafkaTemplate<String, String> kTemplate;

	//topic, 메세지 객체
    public void sendMessage(String message){
        this.kTemplate.send("test_topic", message);
    }
}
```

### consumer
```java
@service
public class Consumer {


    @KafkaListener(topics = "test_topic", groupId = "consumer1")
    public void consume(String massage) throws IOException{
        System.out.println("receive message: "+ massage);
    }
}
```


## 4. kafka 클러스터 구성
다수의 브로커를 연결

## 5. 알림 서비스 구성
